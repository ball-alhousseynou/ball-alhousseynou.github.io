# Portfolio
---
## Ecommerce

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/ball-alhousseynou/Ecommerce)


<div style="text-align: justify">This project involves classifying products into one of four categories: Electronics, Household, Books, and Clothing & Accessories. The dataset used for this task contains e-commerce text data specifically designed for classification purposes. </div>
<br>
<em>Technologies: Python, Bert, LinearSVC, MultinomialNB, LogisticRegression
<center><img src="images/ecommerce.jpg" /> </center>


---
## Semantic Search

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/semantic_search.html)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/ball-alhousseynou/Semantic-Search)


<div style="text-align: justify">This project shows how to combine sentence transformers(SBERT) and elasticsearch to find similar papers. SBERT give the embedding(dense vectors) for each papers. ElasticSearch store the dense vectors and use them for document scoring. As corpus, I use all EMNLP publications from 2016 - 2018. </div>
<br>
<em>Technologies: Python, SBert, Sentence transformer, Elasticsearch
<center><img src="images/search_query.png" /> </center>


---
## Auto Insurance

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/autoinsurance.html)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/ball-alhousseynou/Kaggle-Challenge-Auto-Insurance)


<div style="text-align: justify">Based on information about cars, I predict the probability of crash. General description and data are available on <a href="https://www.kaggle.com/competitions/auto-insurance-fall-2017">Kaggle</a>. The dataset has a lot of features. This gives interesting possibilities for feature transformation and data visualization.</div>

<br>
<em>Technologies: Python, EDA, Logistic regression, Random forest, Gradient boosting 
<center><img src="images/autoinsurance.png" width="700" height="350"/></center>



---
## Notification Pass Logement

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/ball-alhousseynou/notification-pass-logement)


<div style="text-align: justify">
Frustrated with repeatedly checking the Pass Logement platform for new apartment listings, I developed an automated solution. <strong>Notification Pass Logement</strong> streamlines the process by scraping the platform for updates and sending real-time notifications, ensuring no opportunity is missed.  

The system utilizes <strong>Scrapy</strong> for data extraction and <strong>Prefect</strong> for workflow orchestration, enabling seamless scheduling, monitoring, and deployment. Users can receive alerts whenever a new listing appears, eliminating the need for manual checks.
</div>

<br>
<em>Technologies: Python, Scrapy, Prefect</em>  
<center><img src="images/passlogement.png" width="700" height="350"/></center>

---
## Emergency Housing

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/emergencyhousing.html)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/ball-alhousseynou/emergency-housing)

<div style="text-align: justify">The datasets are from the competition hosted in 2019 by <a href="https://www.datascience-olympics.com/">datascience olympics</a>. A tutorial notebook which included the custom metric competition_scorer and a baseline submission using a logistic regression model. I trained an XGBoost model.</div>

<br>
<em>Technologies: Python, Sklearn, XGBoost 
<center><img src="images/emergencyhousing.png"/></center>
<br>

---
